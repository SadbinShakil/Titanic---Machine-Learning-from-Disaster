{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\SHAKIL\\titanic\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean       0.523008\n",
       "std        1.102743\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        8.000000\n",
       "Name: SibSp, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SibSp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    678\n",
       "Survived       678\n",
       "Pclass         678\n",
       "Name           678\n",
       "Sex            678\n",
       "Age            521\n",
       "SibSp          678\n",
       "Parch          678\n",
       "Ticket         678\n",
       "Fare           678\n",
       "Cabin          141\n",
       "Embarked       676\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Parch'].describe()\n",
    "df[df['Parch']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.drop(['PassengerId','Survived','Pclass','Name','Ticket','Fare','Cabin','Embarked'],axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch\n",
       "0    male  22.0      1      0\n",
       "1  female  38.0      1      0\n",
       "2  female  26.0      0      0\n",
       "3  female  35.0      1      0\n",
       "4    male  35.0      0      0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df2['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch\n",
       "630  male  80.0      0      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['Age']==80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing Age \n",
    "df2['Age']=df2['Age']/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex     Age  SibSp  Parch\n",
       "0    male  0.2750      1      0\n",
       "1  female  0.4750      1      0\n",
       "2  female  0.3250      0      0\n",
       "3  female  0.4375      1      0\n",
       "4    male  0.4375      0      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Dummie variables for Sex Column\n",
    "dummies=pd.get_dummies(df2['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   female  male\n",
       "0       0     1\n",
       "1       1     0\n",
       "2       1     0\n",
       "3       1     0\n",
       "4       0     1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex     Age  SibSp  Parch  female  male\n",
       "0    male  0.2750      1      0       0     1\n",
       "1  female  0.4750      1      0       1     0\n",
       "2  female  0.3250      0      0       1     0\n",
       "3  female  0.4375      1      0       1     0\n",
       "4    male  0.4375      0      0       0     1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Concating dummie variables with original dataset\n",
    "df3=pd.concat([df2,dummies],axis='columns')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch  female\n",
       "0  0.2750      1      0       0\n",
       "1  0.4750      1      0       1\n",
       "2  0.3250      0      0       1\n",
       "3  0.4375      1      0       1\n",
       "4  0.4375      0      0       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Excluding original sex column along with one dummie column\n",
    "df4=df3.drop(['Sex','male'],axis='columns')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age       177\n",
       "SibSp       0\n",
       "Parch       0\n",
       "female      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_age=df4['Age'].fillna(df4['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age       177\n",
       "SibSp       0\n",
       "Parch       0\n",
       "female      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  SibSp  Parch  female     Age\n",
       "0  0.2750      1      0       0  0.2750\n",
       "1  0.4750      1      0       1  0.4750\n",
       "2  0.3250      0      0       1  0.3250\n",
       "3  0.4375      1      0       1  0.4375\n",
       "4  0.4375      0      0       0  0.4375"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.concat([df4,New_age],axis='columns')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch  female     Age\n",
       "0      1      0       0  0.2750\n",
       "1      1      0       1  0.4750\n",
       "2      0      0       1  0.3250\n",
       "3      1      0       1  0.4375\n",
       "4      0      0       0  0.4375"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6=df5.drop(['Age'],axis='columns')\n",
    "df6=pd.concat([df6,New_age],axis='columns')\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp     0\n",
       "Parch     0\n",
       "female    0\n",
       "Age       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df6\n",
    "y=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912457912457912"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318435754189944"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model2= tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7318435754189944"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model3=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7486033519553073"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train)\n",
    "model3.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model4= GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7597765363128491"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x_train,y_train)\n",
    "model4.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten=x_train.values.reshape(len(x_train),4)\n",
    "x_test_flatten=x_test.values.reshape(len(x_test),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 3s 3ms/step - loss: 0.6785 - accuracy: 0.6389\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7104 - accuracy: 0.5957\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6656 - accuracy: 0.6359\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6127\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6434\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6681 - accuracy: 0.6208\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.6234\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6308\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6259\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.6043\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6337\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.6194\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6345\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.6370\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6297\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6296\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.6083\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.6109\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6682 - accuracy: 0.6117\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6618 - accuracy: 0.6240\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6285\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6351\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6279\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6380\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6226\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.6315\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.6091\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6735 - accuracy: 0.5993\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6274\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6593 - accuracy: 0.6280\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6731 - accuracy: 0.5998\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6313\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.6671\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6399\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6406\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.6341\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6162\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6267\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6510\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.6137\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6319\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6276\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.59 - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6084\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6449 - accuracy: 0.6514\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6599 - accuracy: 0.6207\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.6155\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.5902\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6433\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6124\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6370\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6234\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6091\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6244\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6352\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6171\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6137\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6278\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6320\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6274\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6010\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6282\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6068\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6346 - accuracy: 0.6353\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6376\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.6561\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.5811\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6313\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6228\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6438\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6352\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6340\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6084\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6231 - accuracy: 0.5999\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6437\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.6234\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6171\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6368\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.6285\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6129\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.5985\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6408\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6379\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5740 - accuracy: 0.6212\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6018\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.6586\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.6183\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.6083\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.6703\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.6622\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7828\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5371 - accuracy: 0.8228\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.8032\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7965\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8179\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5391 - accuracy: 0.7994\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.8349\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7943\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7792\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5292 - accuracy: 0.8004\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5115 - accuracy: 0.8158\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7961\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5262 - accuracy: 0.8014\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.8206\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.8040\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8009\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7817\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8110\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.7972\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8251\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.8407\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5092 - accuracy: 0.8032\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.7739\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7894\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.8084\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.8080\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8290\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.8055\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8002\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.8213\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.8267\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7933\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7821\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.8171\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7837\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8040\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7962\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8031\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8124\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.8164\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8058\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.8166\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8144\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8010\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.8188\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8073\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8159\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.8197\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8048\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5053 - accuracy: 0.7817\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7886\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5014 - accuracy: 0.7915\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.8053\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8080\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.8110\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7943\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8244\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.8189\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.7984\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8046\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7937\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4761 - accuracy: 0.8165\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7937\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.8159\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4983 - accuracy: 0.7988\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8021\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8254\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.8011\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8112\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.8190\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4826 - accuracy: 0.8041\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.8024\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8159\n",
      "Epoch 163/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.7927\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7940\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.8160\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8112\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8015\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.8200\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5054 - accuracy: 0.7903\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.8280\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.8172\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4811 - accuracy: 0.8085\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8048\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8165\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.8285\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.8138\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.8026\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8209\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7898\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4672 - accuracy: 0.8171\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.8174\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8032\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8040\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7975\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.8233\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8354\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.8111\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5031 - accuracy: 0.7908\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8040\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7913\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.8193\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4863 - accuracy: 0.8057\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7979\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8063\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8225\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.7989\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7975\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8159\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.8189\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4623 - accuracy: 0.8171\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.8041\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8001\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4789 - accuracy: 0.8070\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.8198\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.8184\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8248\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.8156\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8071\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8171\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4832 - accuracy: 0.8051\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4291 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4577 - accuracy: 0.8274\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.8076\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.8179\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.8225\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.8267\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8229\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.8190\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4815 - accuracy: 0.8058\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7973\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7977\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8053\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.8215\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.8151\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8206\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8014\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.8039\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8331\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8088\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.8181\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8062\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.8111\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.8419\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7947\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8164\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4998 - accuracy: 0.8011\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8095\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.8123\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4370 - accuracy: 0.8346\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7949\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8095\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.8106\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5019 - accuracy: 0.7978\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8116\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8018\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.8129\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.8154\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.8193\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8176\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8114\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.8272\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4712 - accuracy: 0.8086\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5496 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4660 - accuracy: 0.8266\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.8164\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8061\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.8088\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5005 - accuracy: 0.8014\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.8319\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.8281\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.8285\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8348\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8221\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7975\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8087\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.8197\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.8213\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.8287\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.8101\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8020\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.8425\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.8167\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7931\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.8242\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8415\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.8158\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8151\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.8201\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.8263\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.8162\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.8114\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4196 - accuracy: 0.8519\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.8316\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.8167\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4959 - accuracy: 0.8039\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8050\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8125\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.8257\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.8136\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.8108\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8390\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4674 - accuracy: 0.8170\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.8159\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.8324\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.8172\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.8241\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.8174\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8077\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4617 - accuracy: 0.8289\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8301\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.8231\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8071\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.8140\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.8320\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4722 - accuracy: 0.8189\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.8203\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4874 - accuracy: 0.8136\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.8139\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8205\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.8337\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.8216\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.8381\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8155\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.78 - 0s 1ms/step - loss: 0.4862 - accuracy: 0.8108\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.8206\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.8134\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8204\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.8265\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.8292\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.8343\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.8122\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4882 - accuracy: 0.8068\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.8198\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8112\n",
      "Epoch 323/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4786 - accuracy: 0.8160\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8080\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8300\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.8313\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8226\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4424 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4676 - accuracy: 0.8173\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.8373\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.8236\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8411\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8249\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8266\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8260\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.8115\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4673 - accuracy: 0.8126\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5006 - accuracy: 0.7978\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.8280\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8325\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.7928\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.8239\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.8172\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.8120\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.8149\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8475\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8062\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.8157\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.8190\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.8252\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8167\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7935\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8025\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5708 - accuracy: 0.75 - 0s 1ms/step - loss: 0.4784 - accuracy: 0.8057\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4975 - accuracy: 0.7987\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.8274\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.8061\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8094\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.8143\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8195\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6925 - accuracy: 0.62 - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7859\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8053\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8074\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4697 - accuracy: 0.8201\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8106\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8309\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.8122\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8109\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8392\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4625 - accuracy: 0.8188\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8183\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.8201\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8193\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.8276\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8378\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.8247\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8163\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.8291\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8364\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.8136\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8153\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.8212\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7909\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.8340\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7944\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8104\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8210\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.8193\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8132\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.8239\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8220\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.8144\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.8170\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4518 - accuracy: 0.8273\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.8134\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.8194\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4539 - accuracy: 0.8315\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8276\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.8118\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.8228\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8105\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.8247\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.8307\n",
      "Epoch 403/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8311\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.8315\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.8381\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.8405\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.8149\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8262\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.8285\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.8286\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.8274\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.8469\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4764 - accuracy: 0.8167\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.8420\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.8346\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.8155\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8449\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8437\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.8321\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8219\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.8043\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8253\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4989 - accuracy: 0.7962\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8309\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.8236\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8378\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4728 - accuracy: 0.8107\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.8314\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.81 - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8255\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.8229\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8216\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.8119\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.8345\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.8129\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.8345\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.8265\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8256\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.8189\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.90 - 0s 1ms/step - loss: 0.4424 - accuracy: 0.8406\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.8352\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4053 - accuracy: 0.8630\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8502\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8289\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.8107\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.8097\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7978\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8109\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.8367\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8312\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8276\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.8346\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.87 - 0s 1ms/step - loss: 0.4595 - accuracy: 0.8284\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7872\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.8449\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8315\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8129\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.8283\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8076\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.8216\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7904\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.8251\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.8010\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.8030\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.8423\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8447\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.84 - 0s 1ms/step - loss: 0.4590 - accuracy: 0.8286\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8318\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8335\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8138\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.8420\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.8129\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.8305\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7973\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.8301\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8358\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4443 - accuracy: 0.8352\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8126\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.8359\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.8328\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4586 - accuracy: 0.8213\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8038\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.8172\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.8428\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8151\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7999\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8052\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.8142\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4608 - accuracy: 0.8216\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8282\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8333\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.8217\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.8252\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.8303\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.8283\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.8104\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.8424\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.8303\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.8313\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.8258\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4218 - accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a9abfa04c8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5=keras.Sequential([\n",
    "    keras.layers.Dense(4,input_shape=(4,),activation='sigmoid'),\n",
    "    keras.layers.Dense(3,activation='sigmoid'),\n",
    "    keras.layers.Dense(3,activation='sigmoid'),\n",
    "    keras.layers.Dense(2,activation='sigmoid'),\n",
    "    keras.layers.Dense(2,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "model5.fit(x_train_flatten,y_train,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.7709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5466354489326477, 0.7709497213363647]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(x_test_flatten,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model5.predict(x_test_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76603824, 0.34076905], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predic=[np.argmax(i) for i in prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[90, 15],\n",
       "       [26, 48]])>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=tf.math.confusion_matrix(labels=y_test,predictions=y_predic)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(24.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAFBCAYAAAAIZQhgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWWklEQVR4nO3de7id85338fe3CSPqEEGIQ9X5VE0Qqh20g2oZrcMzZtoLdapoPZ6LHhlardago3p6VAkZdWpQmmGMUqIOnWoJQqN4gkoFEUQcq5Ls7/PHXtHdNFnZWbnXXvfK7/3KdV97rXut9Vtfif25vr/7GJmJJC3r3tHpAiRpIBh2kopg2EkqgmEnqQiGnaQiGHaSimDYSaq9iDguIqZExEMRcXxj3bCIuDkipjZ+rtZsDMNOUq1FxHuAo4AdgZHAPhGxKXAiMDEzNwUmNp4vkmEnqe62BH6TmW9k5lzgdmB/YF/g4sZ7Lgb2azaIYSep7qYAu0bE6hGxIrA3sD6wVmY+C9D4ObzZIIPbXmaL5rzwhOexdakh6+zS6RK0FOa+9XS08rlWf2eXX3Pjo4ExfVaNzcyx859k5sMR8S3gZuA14AFg7pJ+T23DTlIZGsE2djHvGQeMA4iI04HpwHMRMSIzn42IEcDMZmM4jZVUjZ55rS39EBHDGz/fBRwAjAeuAw5tvOVQ4NpmY9jZSapG9rRz9GsiYnVgDvC/M/OliDgTuCoijgT+CBzYbADDTlI1etoXdpn5NxuCM/NFYPf+jmHYSapEtrezW2qGnaRqtLGzq4JhJ6kadnaSitDPPaudYthJqoadnaQiuM1OUgncGyupDHZ2kopgZyepCO6NlVQEOztJRXCbnaQi1Lyz83p2kopgZyepGk5jJZUg072xkkpQ8212hp2kajiNlVQEOztJRfAMCklFsLOTVAS32Ukqgp2dpCLY2UkqgmEnqQSeQSGpDHZ2korgDgpJRbCzk1SEmnd2XrxTUhHs7CRVw2mspCLUfBpr2Emqhp2dpCIYdpKK4DRWUhHs7CQVwc5OUhHs7CQVwc5OUhHs7CQVwbCTVITMTlfQlGEnqRp2dpKKYNhJKoJ7YyUVoU2dXURsDlzZZ9VGwCnAUOAo4PnG+pMy84ZFjWPYSaq1zHwUGAUQEYOAp4EJwOHAdzPz2/0Zx7CTVI2B2Ru7O/B4Zk6LiCX6oJdll1SNnp6WlogYExGT+ixjmnzLJ4DxfZ4fGxEPRsR/RMRqzcoz7CRVo8Wwy8yxmTm6zzJ2YcNHxPLAx4GfNlb9CNiY3inus8DZzcpzGiupGu3fG7sXcF9mPgcw/ydARFwAXN/sw4adpEpkT9u32X2SPlPYiBiRmc82nu4PTGn2YcNOUjXaeFBxRKwIfBg4us/qf4+IUUACTy7w2t8w7CRVo43T2Mx8A1h9gXWHLMkYhp2karR/GrtUDDtJ1fDcWElFqHnYeZzdALj0qv9kv4M/w74HHc2lV04A4OVXXuXTx53E3v9yJJ8+7iRefuXVDlephblg7Nk8M/0BJt8/8e11p3z180z7wyQm3fMLJt3zC/b66G4drLBGMltbBohh12ZTn3iSa667kfEXfo9rLj6X2399N9OeepoLL72KnUaP4oYrx7HT6FGMu+yqTpeqhbjkkqv4x30O+pv13//BBYzeYU9G77AnP7/x1g5UVkMtHlQ8UNoWdhGxRUScEBE/iIjvNx5v2a7vq6snnnyK9269BUNWWIHBgwcxetQ2TLzj1/zyzrvYd689ANh3rz249Y67OlypFubOX/2WWS/N7nQZ3aEnW1sGSFvCLiJOAK4AArgbuKfxeHxEnNiO76yrTTbagHsfmMLsl1/hT2++yZ133cOM557nxZdms+YawwBYc41hzJr9cocr1ZI45rOHc9+9N3PB2LMZOnTVTpdTD9nT2jJA2tXZHQnskJlnZuZljeVMYMfGa8XY+N3v4oiDDuSo40/iM5//KpttshGDBg3qdFlaCuedfwmbbfEBth+9JzNmzOSsfz+l0yXVQ4mdHdADrLOQ9SMary1U36sfXHjJ+EW9rev8r499hJ9edA4Xn3sWq66yMhusvy6rrzaU51+YBcDzL8ximN1B15g58wV6ek9g58Jxl7PDDqM6XVItZE9PS8tAadehJ8cDEyNiKvBUY927gE2AYxf1ocbVDsYCzHnhiXofobgEXnxpNquvNpRnZ8xk4u3/w2Xnf4fpz8zg2p/fwqcP+Weu/fkt/MMu7+90meqntdcezowZMwHYb9+9eOihRztckfqjLWGXmTdGxGb0TlvXpXd73XTgnsyc147vrLPPnXQas195hcGDB3PyF45h1VVW5tOH/DNf+Orp/Oz6mxix1pp857STO12mFuKyS3/IB3d9P2usMYwnn5jEqd/4Nh/84AcYOXIrMpNp06bz2WNO6HSZ9VDzMygia3qvx2WpsyvNkHV26XQJWgpz33p6yS4B3PD6aQe39Dv7zq9c1tL3LSnPoJBUjZp3doadpGrU/HQxw05SNezsJBXBm2RLKoKdnaQSDOQBwq0w7CRVw85OUhEMO0lFcAeFpCLY2UkqwQDcJHupGHaSqmHYSSqCh55IKoKdnaQi1DzsvJWipCLY2UmqRF0vBDyfYSepGjWfxhp2kqph2EkqgQcVSyqDYSepCPU+ptiwk1QNp7GSymDYSSqC01hJJXAaK6kMdnaSSmBnJ6kMdnaSSlDz++0YdpIqYthJKkHdOzsv3impCIadpGr0tLj0Q0QMjYirI+KRiHg4It4fEcMi4uaImNr4uVqzMQw7SZXIntaWfvo+cGNmbgGMBB4GTgQmZuamwMTG80Uy7CRVol1hFxGrALsC4wAy863MnA3sC1zceNvFwH7NxjHsJFWijZ3dRsDzwEURcX9EXBgR7wTWysxnARo/hzcbxLCTVI2MlpaIGBMRk/osYxYYeTCwHfCjzNwWeJ3FTFkXxkNPJFWi1UNPMnMsMLbJW6YD0zPzt43nV9Mbds9FxIjMfDYiRgAzm32PnZ2kSmRPtLQsdtzMGcBTEbF5Y9XuwO+B64BDG+sOBa5tNo6dnaRKtPmg4v8DXB4RywNPAIfT26xdFRFHAn8EDmw2gGEnqRKZi+/SWh87JwOjF/LS7v0dw7CTVIm6ny5m2EmqRH+2v3WSYSepElnva3cadpKqYWcnqQiGnaQiOI2VVIS6d3aeQSGpCHZ2kirRzoOKq2DYSapE1x9UHBE7AV8DNmi8P4DMzM3aXJukLtKzDHR2FwFfBu4F5rW3HEndalmYxr6Smf/V9kokdbW6741dZNhFxHsbD2+NiDOAnwF/nv96Zj7Y5tokdZFuPs7uhws837nP46T3BhiSBHRxZ5eZuwBExAaZOa3vaxGxQbsLk9Rd6r6Doj8HFU/o5zpJBcuMlpaB0myb3WbAlsCqEfHxPi+tAqzQ7sIkdZdu3ma3NXAAMJS/vrb7q8DR7SxKUvep+zS22Ta7CcCEiNg5M381gDVJ6kLLwnF2h0bEpxZcmZkL3shWUsG6eRo73y19Hq8A7A881Z5y/mKX9x7R7q9Qm0wY5lFJJeraaex8mXll3+cRcSlwc9sqktSVloVp7II2pPeiAJL0tq7v7CLiJXrPmIDe4/JmASe2syhJqlrTsIuIAEYCTzdW9WTWfTOkpE6oezA0DbvMzIiYkJnbD1RBkrpT3aex/Tld7O6I2K7tlUjqat18utjgzJxL79VOjoqIx4HX+cuVig1ASW+r+VXZm05j7wa2A/YboFokdbGk3tPYZmEXAJn5+ADVIqmL9dR8D0WzsFszIj6/qBcz8zttqEdSl+rp4s5uELAS1Py/QFItdPM09tnM/MaAVSKpq3XzDop6x7SkWunmzm73AatCUtfr2s4uM2cNZCGSulvXhp0kLYlunsZKUr/V/Laxhp2kanTzcXaS1G81P4GiX1c9kaSuZ2cnqRLujZVUhJ5wm52kArjNTlIRelpc+iMiBkXE/RFxfeP5jyPiDxExubGMWtwYdnaSKtHm4+yOAx4GVumz7kuZeXV/B7Czk1SJHqKlZXEiYj3gH4ELl6Y+w05SJbLFpR++B3yZv531/ltEPBgR342Iv1vcIIadpEr0RGtLRIyJiEl9ljHzx4yIfYCZmXnvAl/3r8AWwA7AMOCExdXnNjtJlWj1OLvMHAuMXcTLfw98PCL2BlYAVomIyzLz4Mbrf46Ii4AvLu577OwkVaId09jM/NfMXC8z3w18Arg1Mw+OiBEAERH03gFxyuLqs7OTVIkBvurJ5RGxJr1XVJ8MfGZxHzDsJFWi3aeLZeZtwG2Nx7st6ecNO0mV8NxYSUXIep8aa9hJqoadnaQiGHaSiuBVTySpBuzsJFXCu4tJKoLb7CQVwbCTVIS676Aw7CRVwm12korgNFZSEZzGSipCT83jzrCTVAmnsZKKUO++zrCTVBE7O0lF8NATSUVwB4WkItQ76gw7SRVxm52kItR9GuvFOyUVwc5OUiXq3dcZdpIq4jY7SUWo+zY7w05SJeoddYadpIo4jZVUhKx5b2fYSaqEnZ2kIriDonDD11mTr33/JFYfPoyenh7+87LruWrcNQAceMT+/NPh+zNv7jx+PfE3nHPa+R2uVov0jmDXm07nzRmzuPuQs1hj563Z6pSD4B3BvNff5P7jzuONJ5/rdJUdVe+oM+zabt7cefzgG+fy6O+msuI7h/DjG8dy9x2TGLbmauz6kZ05ePcjmfPWHFZbfWinS1UTGx21F69OfZrlVh4CwDbfOpJ7Dvs2r019hg0O+zCbfW5/Jh93Xoer7Ky6d3aeLtZmL86cxaO/mwrAG6//iScfm8bwEWtwwKf25ZJzfsKct+YA8NKLsztZpppYYcQwhu+xLX+8/Jd/WZnJ4JV6g2+5lVfkzRkvdai6+uhpcRkoAx52EXH4QH9nXYxYb202e8+mTLnvYd618fqMfN82jLv+XM695ntsOXLzTpenRdj6m5/i4W/+BPIvv5oPfGEs77v8BPa47xzWO3BnHvu/13WwwnrIFv8MlE50dqd24Ds7bsiKQzjjwlP53inn8MZrbzBo0CBWWXVljtznGM755nn82/lf73SJWojhH96Wt154hZcf/MNfrd9ozN789qBvcct2x/LUFbez1akHd6jC+qh7Z9eWbXYR8eCiXgLWavK5McAYgA1X3ZThK67ThuoG3qDBgzjjwlO56We3cNvP7wRg5rPPc9sNvY9/P/kRenp6GDpsVWbPermTpWoBw3bYnLX23I7hu4/iHX+3HMutNIQdL/syK22yDrPvfxyAZ669i/eNP7HDlXZeqcfZrQV8BFhwQ0YAv17UhzJzLDAWYKd1PlTvv7klcPLZX+bJqX9k/Nifvr3ujht/xfY7b8t9d01m/Y3WY7nllzPoauiR06/gkdOvAGD1D2zJxp/dh3sOO5s9HzyPd260Nq8/MYM1dt2G1/7f0x2utPNKPc7uemClzJy84AsRcVubvrOWRu64DXsf+BEe+/3jXHLzhQD86IwL+K8rbuAr3zmBy2+9iLlz5vCN487ocKXqr5zXwwNfHMvocZ8je5I5L7/OA8d72FBP1rs/iaxpgctSZ1eak3tGdLoELYWPzRjf0n3CDtnggJZ+Zy+d9rMBuS+Zx9lJqkTduxPDTlIl6n5QsWEnqRKl7o2VVJhS98ZKKozTWElFqPs01gsBSKpEu04Xi4gVIuLuiHggIh6KiFMb6zeMiN9GxNSIuDIilm82jmEnqRKZ2dLSD38GdsvMkcAo4KMRsRPwLeC7mbkpvWdrHdlsEMNOUiV6yJaWxclerzWeLtdYEtgNuLqx/mJgv2bjGHaSKtHqNDYixkTEpD7LmAXHjohBETEZmAncDDwOzM7MuY23TAfWbVafOygkVaLVHRR9LwDS5D3zgFERMRSYAGy50BKaMOwkVWIgDj3JzNmNi4nsBAyNiMGN7m494Jlmn3UaK6kS7dpBERFrNjo6ImIIsAfwMPBL4J8abzsUuLbZOHZ2kirRxjMoRgAXR8Qgehu0qzLz+oj4PXBFRJwG3A+MazaIYSepEu06qDgzHwS2Xcj6J4Ad+zuOYSepEnU/XcxtdpKKYGcnqRJ1ver5fIadpErUfRpr2EmqRN2vemLYSapE3e8uZthJqkS9o86wk1QRt9lJKoJhJ6kIHnoiqQh2dpKK4KEnkorgNFZSEZzGSiqCnZ2kItjZSSqCOygkFaHu58Z68U5JRbCzk1QJp7GSilD3aaxhJ6kSdnaSimBnJ6kIdnaSimBnJ6kIdnaSipDZ0+kSmjLsJFXCc2MlFcGrnkgqgp2dpCLY2UkqgoeeSCqCh55IKoLTWElFcAeFpCLUvbPzSsWSimBnJ6kS7o2VVIS6T2MNO0mVcAeFpCLY2UkqgtvsJBXBMygkFcHOTlIR6r7NzoOKJVUiW/yzOBHxHxExMyKm9Fn39Yh4OiImN5a9FzeOYSepEpnZ0tIPPwY+upD1383MUY3lhsUN4jRWUiXaNY3NzDsi4t1LO46dnaRKZIvLUjg2Ih5sTHNXW9ybo+4bFZdVETEmM8d2ug61xn+/6kTEGGBMn1VjF/y7bXR212fmexrP1wJeoDcvvwmMyMwjmn6PYdcZETEpM0d3ug61xn+/gbVg2PX3tb6cxkrqOhExos/T/YEpi3rvfO6gkFRrETEe+BCwRkRMB74GfCgiRtE7jX0SOHpx4xh2neP2nu7mv98AycxPLmT1uCUdx212korgNjtJRTDsOiAiPhoRj0bEYxFxYqfrUf8t7NQldQfDboBFxCDgh8BewFbAJyNiq85WpSXwYxZ+6pJqzrAbeDsCj2XmE5n5FnAFsG+Ha1I/ZeYdwKxO16ElZ9gNvHWBp/o8n95YJ6mNDLuBFwtZ5y5xqc0Mu4E3HVi/z/P1gGc6VItUDMNu4N0DbBoRG0bE8sAngOs6XJO0zDPsBlhmzgWOBW4CHgauysyHOluV+qtx6tJdwOYRMT0ijux0Teofz6CQVAQ7O0lFMOwkFcGwk1QEw05SEQw7SUUw7AoWEfMaNxieEhE/jYgVl2KsD0XE9Y3HH292NZeIGBoRx7TwHV+PiC+2WqPKZtiV7U+NGwy/B3gL+EzfF6PXEv8/kpnXZeaZTd4yFFjisJOWhmGn+e4ENomId0fEwxFxLnAfsH5E7BkRd0XEfY0OcCV4+7p8j0TEr4AD5g8UEYdFxDmNx2tFxISIeKCxfAA4E9i40VWe1XjflyLinsZ9QE/tM9bJjWv/3QJsPmB/G1rmGHYiIgbTe3293zVWbQ5ckpnbAq8DXwH2yMztgEnA5yNiBeAC4GPALsDaixj+B8DtmTkS2A54CDgReLzRVX4pIvYENqX38lejgO0jYteI2J7e0+m2pTdMd6j4P10F8YY7ZRsSEZMbj++k9yYm6wDTMvM3jfU70XuR0f+JCIDl6T1dagvgD5k5FSAiLuOvb3Q8327ApwAycx7w8kLu3r5nY7m/8XwlesNvZWBCZr7R+A7PIVbLDLuy/SkzR/Vd0Qi01/uuAm5e8A5PfW5jV4UAzsjM8xf4juMr/A4VzmmsFuc3wN9HxCYAEbFiRGwGPAJsGBEbN963sNvdAUwEPtv47KCIWAV4ld6ubb6bgCP6bAtcNyKGA3cA+0fEkIhYmd4ps9QSw05NZebzwGHA+Ih4kN7w2yIz36R32vrfjR0U0xYxxHHAP0TE74B7ga0z80V6p8VTIuKszPwF8BPgrsb7rgZWzsz7gCuBycA19E61pZZ41RNJRbCzk1QEw05SEQw7SUUw7CQVwbCTVATDTlIRDDtJRTDsJBXh/wNs69osZq1CtwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (5,5))\n",
    "ax=sn.heatmap(cm, annot=True)\n",
    "\n",
    "bottom, top=ax.get_ylim()\n",
    "ax.set_ylim(bottom+.5,top-.5)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83       105\n",
      "           1       0.80      0.66      0.73        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.80      0.77      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C = 10))])\n",
    "pipe.fit(x_train_flatten, y_train)\n",
    "pipe.score(x_test_flatten, y_test)\n",
    "\n",
    "print(classification_report(y_test, pipe.predict(x_test_flatten)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(r\"C:\\Users\\SHAKIL\\titanic\\test.csv\")\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch\n",
       "0    male  34.5      0      0\n",
       "1  female  47.0      1      0\n",
       "2    male  62.0      0      0\n",
       "3    male  27.0      0      0\n",
       "4  female  22.0      1      1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=test_data.drop(['PassengerId','Pclass','Name','Ticket','Fare','Cabin','Embarked'],axis='columns')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  SibSp  Parch  female\n",
       "0  34.5      0      0       0\n",
       "1  47.0      1      0       1\n",
       "2  62.0      0      0       0\n",
       "3  27.0      0      0       0\n",
       "4  22.0      1      1       1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies2=pd.get_dummies(test_data['Sex'])\n",
    "test=pd.concat([test_data,dummies2],axis='columns')\n",
    "test=test.drop(['Sex','male'],axis='columns')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age       86\n",
       "SibSp      0\n",
       "Parch      0\n",
       "female     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.453947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.355263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.289474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch  female       Age\n",
       "0      0      0       0  0.453947\n",
       "1      1      0       1  0.618421\n",
       "2      0      0       0  0.815789\n",
       "3      0      0       0  0.355263\n",
       "4      1      1       1  0.289474"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age=test['Age'].fillna(test['Age'].mean())\n",
    "test=test.drop(['Age'],axis='columns')\n",
    "test=pd.concat([test,Age],axis='columns')\n",
    "test['Age']=test['Age']/76\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34845126, 0.6566207 ]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.predict([[1,0,1,0.618421]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model5.predict([[1,0,1,0.618421]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp     0\n",
       "Parch     0\n",
       "female    0\n",
       "Age       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removing feature using correlation\n",
    "\n",
    "df=pd.read_csv(r\"C:\\Users\\SHAKIL\\titanic\\train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\",axis=1)   #Feature Matrix\n",
    "y = df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((623, 11), (268, 11))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PassengerId</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Survived</td>\n",
       "      <td>-0.005007</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pclass</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>-0.338481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>0.036847</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.369226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.096067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SibSp</td>\n",
       "      <td>-0.057527</td>\n",
       "      <td>-0.035322</td>\n",
       "      <td>0.083081</td>\n",
       "      <td>-0.308247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>0.159651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Parch</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>0.081629</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>0.414838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Fare</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>-0.549500</td>\n",
       "      <td>0.096067</td>\n",
       "      <td>0.159651</td>\n",
       "      <td>0.216225</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PassengerId  Survived    Pclass       Age     SibSp     Parch  \\\n",
       "PassengerId     1.000000 -0.005007 -0.035144  0.036847 -0.057527 -0.001652   \n",
       "Survived       -0.005007  1.000000 -0.338481 -0.077221 -0.035322  0.081629   \n",
       "Pclass         -0.035144 -0.338481  1.000000 -0.369226  0.083081  0.018443   \n",
       "Age             0.036847 -0.077221 -0.369226  1.000000 -0.308247 -0.189119   \n",
       "SibSp          -0.057527 -0.035322  0.083081 -0.308247  1.000000  0.414838   \n",
       "Parch          -0.001652  0.081629  0.018443 -0.189119  0.414838  1.000000   \n",
       "Fare            0.012658  0.257307 -0.549500  0.096067  0.159651  0.216225   \n",
       "\n",
       "                 Fare  \n",
       "PassengerId  0.012658  \n",
       "Survived     0.257307  \n",
       "Pclass      -0.549500  \n",
       "Age          0.096067  \n",
       "SibSp        0.159651  \n",
       "Parch        0.216225  \n",
       "Fare         1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "#Using Pearson Correlation\n",
    "plt.figure(figsize=(12,5))\n",
    "cor = df.corr()\n",
    "ax=sns.heatmap(cor, annot=True)\n",
    "bottom, top=ax.get_ylim()\n",
    "ax.set_ylim(bottom+.5,top-.5)\n",
    "plt.title(\"Correlation between Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
    "                colname = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(colname)\n",
    "    return col_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features = correlation(df, 0.7)\n",
    "len(set(corr_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch  female     Age\n",
       "0      1      0       0  0.2750\n",
       "1      1      0       1  0.4750\n",
       "2      0      0       1  0.3250\n",
       "3      1      0       1  0.4375\n",
       "4      0      0       0  0.4375"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# excluding sibsp from final dataset\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>female</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  female     Age\n",
       "0      0       0  0.2750\n",
       "1      0       1  0.4750\n",
       "2      0       1  0.3250\n",
       "3      0       1  0.4375\n",
       "4      0       0  0.4375"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7=df6.drop(['SibSp'],axis=1)\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df7\n",
    "y=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=.2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten=x_train.values.reshape(len(x_train),3)\n",
    "x_test_flatten=x_test.values.reshape(len(x_test),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 0.6842 - accuracy: 0.6388\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.6108\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6368\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.6192\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6255\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6455\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6374\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.6105\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6756 - accuracy: 0.6010\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6121\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6341\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6394\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6224\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.6204\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6538 - accuracy: 0.6389\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.6448\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6467\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6211\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5959\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6560 - accuracy: 0.6347\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.6203\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.6181\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6291\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6111\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6668 - accuracy: 0.6107\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6237\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6197\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6065\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6206\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.6305\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6747 - accuracy: 0.5923\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6738 - accuracy: 0.5920\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6272\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6701 - accuracy: 0.5993\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6252\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6627 - accuracy: 0.6124\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6174\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6622 - accuracy: 0.6110\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6421\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.6073\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6226\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6416 - accuracy: 0.6499\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6342\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6288\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.5888\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6299\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6574 - accuracy: 0.6101\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6390\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6649 - accuracy: 0.5947\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.6037\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6076\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6376\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6169\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6043\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6405\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6530 - accuracy: 0.5987\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.5881\n",
      "Epoch 58/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.5968\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6341 - accuracy: 0.6314\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6406 - accuracy: 0.6161\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6160\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.6539\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.6093\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.6275\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6009\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6160\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6169\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6191 - accuracy: 0.6221\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6290\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6203 - accuracy: 0.6130\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6075 - accuracy: 0.6248\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6177 - accuracy: 0.6001\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6303\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.6093 - accuracy: 0.6044\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.6694\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.6336\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6295\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.6176\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.6283\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.6088\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5771 - accuracy: 0.6153\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6439\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.7113\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5780 - accuracy: 0.7668\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7765\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.7880\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7779\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.7820\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7716\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5527 - accuracy: 0.7810\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.7657\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5443 - accuracy: 0.7820\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5547 - accuracy: 0.7770\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7809\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.7938\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5398 - accuracy: 0.7844\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5558 - accuracy: 0.7555\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7755\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5248 - accuracy: 0.7816\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7696\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7977\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5269 - accuracy: 0.7727\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7751\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.7775\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7642\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.7782\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7938\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7676\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7796\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5314 - accuracy: 0.7765\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7783\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5190 - accuracy: 0.7879\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7972\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7893\n",
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5272 - accuracy: 0.7784\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5159 - accuracy: 0.7842\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7789\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7752\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7770\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7844\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5448 - accuracy: 0.7612\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.7922\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5215 - accuracy: 0.7790\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7936\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7791\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8116\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7927\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7904\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7920\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.8041\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7875\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7782\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7676\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7578\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7767\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5191 - accuracy: 0.7837\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8001\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7963\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5218 - accuracy: 0.7748\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5029 - accuracy: 0.7860\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7809\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7822\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7798\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7763\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5112 - accuracy: 0.7834\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4965 - accuracy: 0.7928\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4912 - accuracy: 0.7998\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4988 - accuracy: 0.7974\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5133 - accuracy: 0.7776\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7913\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.7995\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4920 - accuracy: 0.7962\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.7816\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8017\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5221 - accuracy: 0.7742\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5137 - accuracy: 0.7771\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5174 - accuracy: 0.7781\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7942\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7896\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7730\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7854\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.7741\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.7826\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.7561\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7562\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.7879\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7922\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7931\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7955\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7811\n",
      "Epoch 171/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5037 - accuracy: 0.7864\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5132 - accuracy: 0.7790\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7863\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7481\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4999 - accuracy: 0.7874\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7748\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7822\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5051 - accuracy: 0.7875\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7839\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7690\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7680\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7950\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7982\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5153 - accuracy: 0.7801\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7846\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8036\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7882\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.8064\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7783\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7796\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7863\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7866\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.7804\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7718\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8087\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7928\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5000 - accuracy: 0.7921\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4929 - accuracy: 0.7896\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7759\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7755\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.7996\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7867\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5114 - accuracy: 0.7857\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4925 - accuracy: 0.7909\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7813\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5077 - accuracy: 0.7760\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7972\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4970 - accuracy: 0.7937\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5151 - accuracy: 0.7803\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7909\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7635\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7802\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5144 - accuracy: 0.7844\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7763\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7970\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7803\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5065 - accuracy: 0.7858\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7922\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7963\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4986 - accuracy: 0.7909\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4740 - accuracy: 0.8092\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.7966\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.8003\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7681\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.7998\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7687\n",
      "Epoch 227/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7956\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7797\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.8011\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5080 - accuracy: 0.7832\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5205 - accuracy: 0.7697\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4865 - accuracy: 0.7994\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7717\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7930\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7724\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7737\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.8002\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7885\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8017\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7985\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7697\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.7815\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.7805\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7983\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7844\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.7757\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5347 - accuracy: 0.7696\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.7802\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7815\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7858\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.87 - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7897\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7706\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7963\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7840\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7875\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8109\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.8165\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7918\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5261 - accuracy: 0.7792\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7995\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7960\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7776\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7962\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.8046\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5056 - accuracy: 0.7869\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5131 - accuracy: 0.7854\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8039\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.8105\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8003\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7875\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8107\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8007\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5004 - accuracy: 0.7983\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7880\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7846\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.7818\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5033 - accuracy: 0.7901\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7776\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.7855\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7934\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5063 - accuracy: 0.7899\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5163 - accuracy: 0.7749\n",
      "Epoch 283/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7822\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8006\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7987\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8074\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7930\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7975\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.8142\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7901\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7551\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5125 - accuracy: 0.7784\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7724\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7984\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8031\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.8138\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7876\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7952\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7709\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.7673\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7946\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5278 - accuracy: 0.7789\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8008\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5321 - accuracy: 0.7667\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8100\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5072 - accuracy: 0.7853\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5141 - accuracy: 0.7811\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.7952\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7496\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7687\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7883\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7953\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7937\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7832\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5041 - accuracy: 0.7921\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7991\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5052 - accuracy: 0.7911\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5196 - accuracy: 0.7742\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5185 - accuracy: 0.7789\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5111 - accuracy: 0.7793\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5001 - accuracy: 0.7901\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.8008\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7769\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8053\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7804\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8102\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7969\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7922\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.8117\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8046\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5229 - accuracy: 0.7753\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7723\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8143\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5064 - accuracy: 0.7910\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5117 - accuracy: 0.7851\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7909\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4942 - accuracy: 0.7943\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7903\n",
      "Epoch 339/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5246 - accuracy: 0.7755\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5182 - accuracy: 0.7786\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7821\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7918\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7793\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7942\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5589 - accuracy: 0.7592\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7865\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5168 - accuracy: 0.7829\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5024 - accuracy: 0.7880\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4841 - accuracy: 0.8091\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7774\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7954\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7763\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7998\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.8063\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7949\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.8111\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8115\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7710\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7772\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7653\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7899\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7951\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7915\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.8128\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.8090\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.8294\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8018\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7859\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7931\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.8037\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4712 - accuracy: 0.8180\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7865\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7872\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7919\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7830\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7959\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5175 - accuracy: 0.7808\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.8062\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.8033\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7738\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7845\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4987 - accuracy: 0.7957\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7798\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.8055\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7774\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4824 - accuracy: 0.8071\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5082 - accuracy: 0.7809\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7958\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.7980\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.8133\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8132\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.8336\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8069\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7899\n",
      "Epoch 395/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7872\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7746\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7715\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8117\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7994\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.8129\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7883\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7859\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.8011\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6473 - accuracy: 0.68 - 0s 1ms/step - loss: 0.4955 - accuracy: 0.7989\n",
      "Epoch 405/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7752\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7987\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7785\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7716\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.7827\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7935\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.7902\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7917\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7862\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.8255\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7850\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8244\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4842 - accuracy: 0.8082\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7860\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.7970\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5032 - accuracy: 0.7957\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7987\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.7887\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5139 - accuracy: 0.7824\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8175\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8129\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7788\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.8032\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.8032\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8018\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4974 - accuracy: 0.8010\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7768\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7920\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7977\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.8125\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7997\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.8052\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.8120\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.8023\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8072\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4899 - accuracy: 0.8062\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7970\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8133\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.8055\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5181 - accuracy: 0.7868\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8204\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5026 - accuracy: 0.7985\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5127 - accuracy: 0.7886\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4993 - accuracy: 0.7956\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.8083\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.8306\n",
      "Epoch 451/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7727\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.8023\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7984\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.8193\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5121 - accuracy: 0.7860\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8043\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8048\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7979\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7990\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5044 - accuracy: 0.7955\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8096\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.7816\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4954 - accuracy: 0.8002\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8048\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8009\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7973\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7828\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7904\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8135\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5199 - accuracy: 0.7837\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7913\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4981 - accuracy: 0.7949\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8068\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8021\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4910 - accuracy: 0.8108\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7979\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7841\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7927\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8001\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7765\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8002\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5150 - accuracy: 0.7864\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 0.8003\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5101 - accuracy: 0.7917\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4831 - accuracy: 0.8090\n",
      "Epoch 486/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7777\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7855\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8135\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8158\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8199\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7997\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8197\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7936\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7866\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4964 - accuracy: 0.8040\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7946\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.8192\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.8294\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7915\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5226 - accuracy: 0.7803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a9b21872c8>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6=keras.Sequential([\n",
    "    keras.layers.Dense(4,input_shape=(3,),activation='sigmoid'),\n",
    "    keras.layers.Dense(3,activation='sigmoid'),\n",
    "    keras.layers.Dense(3,activation='sigmoid'),\n",
    "    keras.layers.Dense(2,activation='sigmoid'),\n",
    "    keras.layers.Dense(2,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model6.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "              )\n",
    "model6.fit(x_train_flatten,y_train,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4921438992023468, 0.7877094745635986]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.evaluate(x_test_flatten,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False), Accuracy is 81.00558659217877 %\n",
      "for DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best'), Accuracy is 76.53631284916202 %\n",
      "for SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False), Accuracy is 81.00558659217877 %\n",
      "for GaussianNB(priors=None, var_smoothing=1e-09), Accuracy is 80.44692737430168 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\SHAKIL\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "models=[model,model2,model3,model4]\n",
    "for i in models:\n",
    "    i.fit(x_train,y_train)\n",
    "    print(\"for {}, Accuracy is {} %\".format(i, i.score(x_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
